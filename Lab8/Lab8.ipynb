{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 8: Video Processing\n",
        "\n",
        "### 1. Objectives\n",
        "This lab introduces the fundamentals of video processing using OpenCV. You will learn how to read, write, and manipulate video files. Key tasks include converting video color spaces, applying image filtering techniques to video frames in real-time, and performing background subtraction to isolate moving objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Submission Guidelines\n",
        "- **File Format**: Jupyter Notebook (.ipynb)\n",
        "- **Naming**: Lab8_StudentFullName_StudentID.ipynb\n",
        "- **Submission**: Compress the Jupyter Notebook file and the generated video files into a single .zip archive and upload it to Moodle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Preparation\n",
        "\n",
        "Run the following cell to install the required packages. You will also need the sample video `5sVideo.mp4` in the same directory as this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-2.3.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Collecting opencv-python\n",
            "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.5-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Using cached fonttools-4.59.1-cp313-cp313-win_amd64.whl.metadata (111 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.9-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\satan\\desktop\\cse457\\lab\\lab8\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Using cached pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\satan\\desktop\\cse457\\lab\\lab8\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\satan\\desktop\\cse457\\lab\\lab8\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
            "Using cached numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
            "Using cached matplotlib-3.10.5-cp313-cp313-win_amd64.whl (8.1 MB)\n",
            "Using cached contourpy-1.3.3-cp313-cp313-win_amd64.whl (226 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.59.1-cp313-cp313-win_amd64.whl (2.3 MB)\n",
            "Using cached kiwisolver-1.4.9-cp313-cp313-win_amd64.whl (73 kB)\n",
            "Using cached pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
            "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, opencv-python, contourpy, matplotlib\n",
            "\n",
            "   ---- ----------------------------------- 1/9 [pillow]\n",
            "   ---- ----------------------------------- 1/9 [pillow]\n",
            "   ---- ----------------------------------- 1/9 [pillow]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   -------- ------------------------------- 2/9 [numpy]\n",
            "   ----------------- ---------------------- 4/9 [fonttools]\n",
            "   ----------------- ---------------------- 4/9 [fonttools]\n",
            "   ----------------- ---------------------- 4/9 [fonttools]\n",
            "   ----------------- ---------------------- 4/9 [fonttools]\n",
            "   ----------------- ---------------------- 4/9 [fonttools]\n",
            "   ----------------- ---------------------- 4/9 [fonttools]\n",
            "   ----------------- ---------------------- 4/9 [fonttools]\n",
            "   -------------------------- ------------- 6/9 [opencv-python]\n",
            "   -------------------------- ------------- 6/9 [opencv-python]\n",
            "   -------------------------- ------------- 6/9 [opencv-python]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ----------------------------------- ---- 8/9 [matplotlib]\n",
            "   ---------------------------------------- 9/9 [matplotlib]\n",
            "\n",
            "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.1 kiwisolver-1.4.9 matplotlib-3.10.5 numpy-2.2.6 opencv-python-4.12.0.88 pillow-11.3.0 pyparsing-3.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Tasks\n",
        "\n",
        "#### Task 1: Processing videos\n",
        "\n",
        "To begin, we'll define a helper function to streamline the video processing workflow. This function will handle reading the input video, applying a given processing function to each frame, and saving the result to a new file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_video(input_path, output_path, process_frame_function):\n",
        "    \"\"\"\n",
        "    Reads a video, applies a function to each frame, and saves the result.\n",
        "    \n",
        "    Args:\n",
        "        input_path (str): Path to the input video file.\n",
        "        output_path (str): Path to save the output video file.\n",
        "        process_frame_function (function): A function that takes a frame (np.array) \n",
        "                                           and returns a processed frame.\n",
        "    \"\"\"\n",
        "    # TODO: Create a video capture object to read the video\n",
        "    #       Use cv2.VideoCapture with the input_path\n",
        "    cap = None\n",
        "    \n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video {input_path}\")\n",
        "        return\n",
        "\n",
        "    # TODO: Get video properties (frame width, height, and frames per second)\n",
        "    # Using: OpenCV's get() method with properties like\n",
        "    #           cv2.CAP_PROP_FRAME_WIDTH, \n",
        "    #           cv2.CAP_PROP_FRAME_HEIGHT, \n",
        "    #           cv2.CAP_PROP_FPS, \n",
        "    #           and cv2.CAP_PROP_FRAME_COUNT\n",
        "    frame_width = None\n",
        "    frame_height = None\n",
        "    fps = None\n",
        "    num_frames = None\n",
        "\n",
        "    print(f\"Video properties: {num_frames} frames, {fps} FPS, {frame_width}x{frame_height} resolution\")\n",
        "\n",
        "    # TODO: Define the codec and create a VideoWriter object,\n",
        "    #       to save the processed video, using cv2.VideoWriter\n",
        "    #       The codec can be defined using cv2.VideoWriter_fourcc\n",
        "    #       fourcc means \"four character code\"\n",
        "    #       The 'mp4v' codec is commonly used for .mp4 files\n",
        "    fourcc = None   # this is the codec for the output video\n",
        "    out = None      # VideoWriter object to write the processed video\n",
        "\n",
        "    print(f\"Processing video: {input_path}...\")\n",
        "    \n",
        "    # Loop through each frame of the video\n",
        "    while cap.isOpened():\n",
        "        # TODO: Read a frame from the video capture object\n",
        "        #       Use cap.read() to get the next frame\n",
        "        ret, frame = None\n",
        "\n",
        "        if not ret:\n",
        "            break  # Break the loop if there are no more frames\n",
        "\n",
        "        # TODO: Apply the processing function to the current frame\n",
        "        processed_frame = None\n",
        "        \n",
        "        # If the processed frame is grayscale, convert it back to BGR to save in a color video file\n",
        "        if len(processed_frame.shape) == 2:\n",
        "            processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # TODO: Write the processed frame to the output file\n",
        "        pass\n",
        "\n",
        "    # TODO: Release the video capture and writer objects, using .release()\n",
        "    pass\n",
        "    \n",
        "    print(f\"Successfully saved processed video to {output_path}\")\n",
        "\n",
        "# Define the input video path\n",
        "input_video_path = '5sVideo.mp4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 2: Convert to Grayscale\n",
        "**Theory:**\n",
        "Grayscale conversion reduces a 3-channel color image (like BGR) to a single-channel image representing pixel intensities (shades of gray). This is often a pre-processing step that simplifies algorithms and reduces computational cost.\n",
        "\n",
        "**Guidance:**\n",
        "1. Define a function that takes a color frame as input.\n",
        "2. Inside the function, use `cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)` to perform the conversion.\n",
        "3. Return the grayscale frame.\n",
        "4. Pass this function to our `process_video` helper to generate the output video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing video: 5sVideo.mp4...\n",
            "Successfully saved processed video to output_grayscale.mp4\n"
          ]
        }
      ],
      "source": [
        "# TODO: Define a function to process each frame to grayscale\n",
        "def to_grayscale(frame):\n",
        "    pass\n",
        "\n",
        "process_video(input_video_path, 'output_grayscale.mp4', to_grayscale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 3: Convert to Binary\n",
        "**Theory:**\n",
        "Binarization converts a grayscale image into a black-and-white image. A threshold value is chosen; pixels with intensity above the threshold become white, and those below become black. This is useful for feature extraction and object segmentation.\n",
        "\n",
        "**Guidance:**\n",
        "1. Define a function that takes a color frame.\n",
        "2. First, convert the frame to grayscale.\n",
        "3. Use `cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)` to binarize the image. Here, 127 is the threshold value and 255 is the maximum value (white).\n",
        "4. The function returns two values; we only need the second one (the thresholded image).\n",
        "5. Pass this new function to the `process_video` helper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing video: 5sVideo.mp4...\n",
            "Successfully saved processed video to output_binary.mp4\n"
          ]
        }
      ],
      "source": [
        "# TODO: Define a function to process each frame to binary\n",
        "def to_binary(frame):\n",
        "    pass\n",
        "\n",
        "process_video(input_video_path, 'output_binary.mp4', to_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 4: Apply Gaussian Blurring Filter\n",
        "**Theory:**\n",
        "A Gaussian blur is a low-pass filter that smooths an image by averaging pixel values with a weighted average of their neighbors. It's effective for reducing noise and detail.\n",
        "\n",
        "**Guidance:**\n",
        "1. Define a function that accepts a frame.\n",
        "2. Use `cv2.GaussianBlur(frame, (15, 15), 0)` to apply the filter. The `(15, 15)` is the kernel size (must be odd numbers), which determines the extent of blurring. A larger kernel results in more blur.\n",
        "3. Return the blurred frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing video: 5sVideo.mp4...\n",
            "Successfully saved processed video to output_gaussian.mp4\n"
          ]
        }
      ],
      "source": [
        "# TODO: Define a function to apply Gaussian blur to each frame\n",
        "def apply_gaussian_blur(frame):\n",
        "    pass\n",
        "\n",
        "process_video(input_video_path, 'output_gaussian.mp4', apply_gaussian_blur)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 5: Apply Laplacian Filter\n",
        "**Theory:**\n",
        "The Laplacian filter is a high-pass filter used for edge detection. It calculates the second derivative of the image, highlighting regions with rapid intensity changes (edges).\n",
        "\n",
        "**Guidance:**\n",
        "1. Define a function that accepts a frame.\n",
        "2. It's best to apply this filter to a grayscale image to focus on intensity changes. Convert the frame to grayscale first.\n",
        "3. Use `cv2.Laplacian(gray_frame, cv2.CV_64F)` to apply the filter. `cv2.CV_64F` is the data type for the output image to handle negative values from the derivative calculation.\n",
        "4. Convert the result back to an 8-bit image using `cv2.convertScaleAbs()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing video: 5sVideo.mp4...\n",
            "Successfully saved processed video to output_laplacian.mp4\n"
          ]
        }
      ],
      "source": [
        "# TODO: Define a function to apply Laplacian filter to each frame\n",
        "def apply_laplacian(frame):\n",
        "    pass\n",
        "\n",
        "process_video(input_video_path, 'output_laplacian.mp4', apply_laplacian)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 6: Apply High-Boost Filtering\n",
        "**Theory:**\n",
        "High-boost filtering is a sharpening technique that enhances edges. It works by subtracting a blurred version of the image from the original (creating an edge mask) and then adding this mask back to the original image. The formula is: `HighBoost = Original + k * (Original - Blurred)`.\n",
        "\n",
        "**Guidance:**\n",
        "1. Define a function that accepts a frame.\n",
        "2. Create a blurred version of the frame using `cv2.GaussianBlur`.\n",
        "3. Add the original and the blurred images together using `cv2.addWeighted()`. We will use a simplified version: `Sharpened = Original * (1 + k) - Blurred * k`. Let's set `k=1.5`.\n",
        "   - `cv2.addWeighted(original, 2.5, blurred, -1.5, 0)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing video: 5sVideo.mp4...\n",
            "Successfully saved processed video to output_high_boost.mp4\n"
          ]
        }
      ],
      "source": [
        "def apply_high_boost(frame):\n",
        "    # TODO: Create the blurred version of the frame\n",
        "    blurred = None\n",
        "\n",
        "    # TODO: Apply the high-boost formula\n",
        "    #       high_boost = original * 2.5 - blurred * 1.5\n",
        "    high_boost = None\n",
        "    return high_boost\n",
        "\n",
        "process_video(input_video_path, 'output_high_boost.mp4', apply_high_boost)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
